%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% This is needed to prevent the style file preventing citations from linking to 
% the bibliography
\makeatletter
\let\NAT@parse\undefined
\makeatother

\usepackage[dvipsnames]{xcolor}

\newcommand*\linkcolours{ForestGreen}

\usepackage{times}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{amsmath}
\usepackage{breakurl}
\def\UrlBreaks{\do\/\do-}
\usepackage{url,hyperref}
\hypersetup{
colorlinks,
linkcolor=\linkcolours,
citecolor=\linkcolours,
filecolor=\linkcolours,
urlcolor=\linkcolours}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[labelfont={bf},font=small]{caption}
\usepackage[none]{hyphenat}

\usepackage{mathtools, cuted}

\usepackage[noadjust, nobreak]{cite}
\def\citepunct{,\,} % Style file defaults to listing references separately

\usepackage{tabularx}
\usepackage{amsmath}

\usepackage{float}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
\newcommand*\imgres{600}

\newcommand*\GitHubLoc{https://github.com/linted/allocation}

\newcolumntype{Y}{>{\centering\arraybackslash}X}

%\usepackage{parskip}

\usepackage[]{placeins}

% \usepackage{epstopdf}
% \epstopdfDeclareGraphicsRule{.tif}{png}{.png}{convert #1 \OutputFile}
% \AppendGraphicsExtensions{.tif}

\newcommand\extraspace{3pt}

\usepackage{placeins}

\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=0.8pt] (char) {#1};}}
            
\usepackage[framemethod=tikz]{mdframed}

\usepackage{afterpage}

\usepackage{stfloats}

\usepackage{atbegshi}
\newcommand{\handlethispage}{}
\newcommand{\discardpagesfromhere}{\let\handlethispage\AtBeginShipoutDiscard}
\newcommand{\keeppagesfromhere}{\let\handlethispage\relax}
\AtBeginShipout{\handlethispage}

\usepackage{comment}

\newcommand*\todo[0]{\textcolor{red}{TODO }}

%\usepackage[1,2,3,5,6,7]{pagesel} %Discard page 4 as it is blank

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Stack and Heap Allocations: A Cost Comparison
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Michael D. Merrill$^{1}$% <-this % stops a space
\thanks{$^{1}$Michael is a Masters student in Computer Sciences, Georgia Tech,
and a developer for the }%
}


\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Stack and Heap allocations have different allocation costs and use cases.
Incorrect choice of allocation method is often problematic and cause increases in latency,
loss of data, and program instability. I compare the choice of allocation method across various 
implementations and situations to show the cost benefit trade offs of each. 
Finally a quantitative explanation of the results through a high level description of the allocation algorithm internals is provided.
The source code is publicly available at \url{\GitHubLoc}.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Allocation algorithms are designed to limit the overhead related to memory management.
The most common design goals include considerations for computational expenses, effectiveness allocation size, and to provide discrete blocks of memory. 
Stack allocation on commonly used architectures, such as Intel x86, involve changing the value of a register to allocate additional space, and are thus standardized by the architecture.
Dynamic allocation, in contrast, is defined by userspace libraries.
This allows for multiple implementations of allocators, as well as specialized allocators which offer increased performance benefits for their use cases. 

This paper addresses the performance costs incurred through the use of the stack and heap across their various allocation methods. 
A number of test algorithms will be used as measurements. 
Each will attempt to measure a discrete feature and function common to all allocation algorithms. 
Care is taken to ensure that tests do not favor one method over another through intentional use of compiler hints and directives. 
The test algorithms are designed to mimic common, real world use cases of allocated memory as well as the academic and theoretical maximums of each allocation type. 


% \begin{figure}[tbp]
% \centering
% \includegraphics[width=0.97\columnwidth]{loss_spikes.png}
% \caption{ Learning curve with high loss spikes that excessively perturb a trainable parameter distribution. Losses decrease after loss spikes as parameters are updated back to an intelligent distribution. The learning curve is 2500 iteration boxcar averaged. }
% \label{loss_spikes}
% \end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithms}

Algorithm \ref{light_usage_algorithm} is designed to test the baseline performance of the allocator.
Memory of size $S$ is allocated and stored in the variable $M$.
A constant value $C$ is then stored at an arbitrary location within the allocated memory, $M_\text{R}$.
Finally, the memory is deallocated and released to be used by the next iteration or another part of the overall program.
This is continued until the test is finished; a time determined by the experiment implementation.

\begin{algorithm}[h]
\caption{Allocation with Light Usage}
\begin{algorithmic}
% \STATE let $T$ be the total number of successful iterations
% \STATE let $0 < S$ be the number of bytes allocated
% \STATE let $0 \leq R \leq S$ a random index to test
% \STATE let $0 < C$
\WHILE{test is not finished}
  \STATE $M \leftarrow allocate(S)$
  % \IF{$M_\text{R} \neq C $}
  \STATE $M_\text{R} \leftarrow C$
  % \STATE $T \leftarrow T + 1$
%   \ELSE\STATE $C$
  % \ENDIF
  \STATE $deallocate(M)$
\ENDWHILE
\end{algorithmic}
\label{light_usage_algorithm}
\end{algorithm}

Algorithm \ref{struct_usage_algorithm}, in a method similar to algorithm \ref{light_usage_algorithm}, begins by allocating memory and storing it into $M$.
In this case $M$ is considered to be a \textbf{C} style structure or similar object of size $S$. 
All of the members within $M$ are filled with appropriate data, simulating common usage of low level structures.
After the structure is populated, the deallocation method is used to free the memory.
Once again, the algorithm loops until a stop condition is met.

\begin{algorithm}[h]
  \caption{Allocation and Initialization of Data Structure}
  \begin{algorithmic}
    \WHILE{test is not finished}
      \STATE $M \leftarrow allocate(S)$
      \STATE $M_\text{R1} \leftarrow C$
      \STATE $M_\text{R2} \leftarrow C$
      \STATE $M_\text{R3} \leftarrow C$
      % \STATE $T \leftarrow T + 1$
      \STATE $deallocate(M)$
    \ENDWHILE
  \end{algorithmic}
  \label{struct_usage_algorithm}
\end{algorithm}

One of the most common usages of allocated memory is in network operations, which Algorithm \ref{network_usage_algorithm}, attempts to capture.
In a setup phase, prior to starting the benchmarked portion, a connection to a server is established.
During the benchmark loop, memory of size $S$ is allocated and stored in $M$.
Up to $C$ bytes are read from the server into the allocated memory at $M$.
After reading is complete, $M$ is deallocated.
The loop continues until the test is finished, and the socket is closed.

\begin{algorithm}[h]
  \caption{Allocation with Network Usage}
  \begin{algorithmic}
    \STATE $C \leftarrow open()$
    \WHILE{test is not finished}
      \STATE $M \leftarrow allocate(S)$
      \STATE $M_\text{R} \leftarrow read(C)$
      % \STATE $T \leftarrow T + 1$
      \STATE $deallocate(M)$
    \ENDWHILE
    \STATE $close(C)$
  \end{algorithmic}
  \label{network_usage_algorithm}
\end{algorithm}

\todo closing notes about algorithms?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment Methodologies}
Googles open source Benchmark library is a microbenchmark framework developed using the Google Test suite. Benchmark provides a comprehensive environment to gauge code snippet performance with an independent and repeatable approach.
Each benchmark handler is written in \textbf{C++} and handles the test setup and teardown functionality.
The portion of code that is timed is written in \textbf{C} to minimize overhead associated with higher level languages, and to produce binary output which is verifiably identical to the associated algorithms.

A standardized set of tests were devised for each algorithm to measure the differences between uninitialized stack allocations, malloc, initializated stack allocation, and calloc.
Each item in this set of tests were chosen to provide an equal and full comparison between the most common types of allocations.
The set of tests can thus be divided into two groups, initialized and uninitialized allocations.
Care is taken when discussing results to ensure comparisons are conducted between groups or between members of groups to more accurately portray results in real world usage. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments: Algorithm \ref{light_usage_algorithm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments: Algorithm \ref{struct_usage_algorithm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments: Algorithm \ref{network_usage_algorithm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

% Taken together, our CIFAR-10 supersampling results show that ALRC improves stability and lowers losses for learning that would be destabilized by loss spikes and otherwise has little effect. Loss spikes are often encountered when training with high learning rates, high order loss functions or small batch sizes. However, a moderate learning rate was used in MSE experiments so losses did not spike enough to destabilize learning. In contrast, mean quartic error training is unstable so ALRC stabilizes training and lowers losses. Similar results are confirmed for partial-STEM where ALRC stabilizes learning and lowers losses.

% ALRC is designed to complement existing learning algorithms with new functionality. It is effective for any loss function or batch size and can be applied to any neural network trained with a variant of stochastic gradient descent. Our algorithm is also computationally inexpensive, requiring orders of magnitude fewer operations than other layers typically used in neural networks. As ALRC either stabilizes learning or has little effect, this means that it is suitable for routine application to arbitrary neural network training with SGD. In addition, we note that ALRC is a simple algorithm that has a clear effect on learning.

% Nevertheless, ALRC can replace other learning algorithms in some situations. For instance, ALRC is a computationally inexpensive alternative to gradient clipping in high batch size training where gradient clipping is being used to limit perturbations by loss spikes. However, it is not a direct replacement as ALRC preserves the distribution of backpropagated gradients whereas gradient clipping reduces large gradients. Instead, ALRC is designed to complement gradient clipping by limiting perturbations by large losses while gradient clipping modifies gradient distributions.

% The implementation of ALRC in algorithm~\ref{alrc_algorithm} is for positive losses. This avoids the need to introduce small constants to prevent divide-by-zero errors. Nevertheless, ALRC can support negative losses by using standard methods to prevent divide by zero errors. Alternatively, a constant can be added to losses to make them positive without affecting learning.

% ALRC can also be extended to limit losses more than a number of standard deviations below their mean. This had no effect in our experiments. However, preemptively reducing loss spikes by clipping rewards between user-provided upper and lower bounds can improve reinforcement learning\cite{mnih2015human}. Subsequently, we suggest that clipping losses below their means did not improve learning because losses mainly spiked above their means; not below. Some partial-STEM losses did spike below; however, they were mainly for blank or otherwise trivial completions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

% We have developed ALRC to stabilize the training of artificial neural networks by limiting backpropagated losses. Our experiments show that ALRC accelerates convergence and lowers losses for learning that would be destabilized by loss spikes and otherwise has little effect. Further, ALRC is computationally inexpensive, can be applied to any loss function or batch size, does not affect the distribution of backpropagated gradients and has a clear effect on learning. Overall, ALRC complements existing learning algorithms and can be routinely applied to arbitrary neural network training with SGD.

\section{Source Code}

Source code for all experiments detailed in this paper can be found at \url{\GitHubLoc}.

% ALRC increases the rate of convergence and decreases losses for otherwise unstable training by limiting loss spikes. If learning is already stable, it has little affect. Our algorithm is computationally inexpensive, robust to hyperparameter choices and can be applied to any loss function or batch size without affecting backpropagated gradient distributions. It follows that ALRC complements existing learning algorithms and can be applied to any artificial neural network trained with SGD.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \bibliographystyle{ieeetr}
% \bibliography{bibliography}

\section{Acknowledgements}

\noindent This research was funded by .

\clearpage

\end{document}
